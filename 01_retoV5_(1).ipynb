{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6lmm-TfQ7iFd"
      },
      "source": [
        "# Reto: competición de sistemas de clasificación"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J7qjccBX7iFe"
      },
      "source": [
        "En este reto aplicaremos regresión logística a la tarea de clasificación [*california-housing*](https://scikit-learn.org/1.5/datasets/real_world.html#california-housing-dataset).\n",
        "\n",
        "El objetivo de esta tarea es clasificar, con mínimo error, diferentes distritos del estado de California (EEUU) en 6 clases diferentes correspondientes a rangos de precios medios de vivienda, utilizando un conjunto de D=8 características numéricas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L6390RZ07iFf"
      },
      "source": [
        "## 1. Obtención del corpus y partición de datos\n",
        "\n",
        "Ejecuta el siguiente bloque de código, en el que importamos las librerías necesarias, definimos constantes, obtenemos el dataset, barajamos (con una semilla concreta e inalterable) y particionamos los datos en train y test (con una proporción concreta e inalterable).\n",
        "\n",
        "**MUY IMPORTANTE: NO MODIFICAR ESTE BLOQUE DE CÓDIGO, SOLO EJECUTAR.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z2laB0jJ7iFf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26683046-72a9-41fe-dd60-724dfff7974c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "******** INFORMACIÓN BÁSICA DEL DATASET **********\n",
            "D=8, C=6, N_train=16512, N_test=4128\n"
          ]
        }
      ],
      "source": [
        "### NO MODIFIQUES ESTE BLOQUE DE CÓDIGO; SOLO EJECÚTALO ###\n",
        "\n",
        "import warnings; warnings.filterwarnings(\"ignore\"); import numpy as np\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "RANDOM_SEED = 22\n",
        "TEST_SIZE = 0.2\n",
        "\n",
        "### NO MODIFIQUES ESTE BLOQUE DE CÓDIGO; SOLO EJECÚTALO ###\n",
        "\n",
        "corp = fetch_california_housing()\n",
        "X = corp.data.astype(np.float16) # muestras\n",
        "y = corp.target.astype(np.uint)  # etiquetas de clase\n",
        "\n",
        "### NO MODIFIQUES ESTE BLOQUE DE CÓDIGO; SOLO EJECÚTALO ###\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=TEST_SIZE, random_state=RANDOM_SEED)\n",
        "D = X_train.shape[1]; C=np.unique(y_train).size; Ntr = X_train.shape[0]; Nte = X_test.shape[0];\n",
        "\n",
        "print(\"******** INFORMACIÓN BÁSICA DEL DATASET **********\")\n",
        "print(f\"D={D}, C={C}, N_train={Ntr}, N_test={Nte}\")\n",
        "\n",
        "### NO MODIFIQUES ESTE BLOQUE DE CÓDIGO; SOLO EJECÚTALO ###"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OlOzU1g77iFg"
      },
      "source": [
        "## 2. Entrenamiento y evaluación del sistema base (baseline)\n",
        "\n",
        "A continuación podéis obtener una tasa de error de referencia, obtenido con un clasificador de regresión logística entrenado con `tol=0.01`, `C=1`, y `max_iter=10`. Este será nuestro sistema de clasificación base (baseline).\n",
        "\n",
        "Vuestro objetivo será mejorar (lo máximo posible) la tasa de error obtenida con este sistema."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kHWyESF67iFh",
        "outputId": "eca73d35-4d8a-4b92-cb5f-922607279621"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error de clasificación en test (baseline):  59.9%\n"
          ]
        }
      ],
      "source": [
        "# NOTA IMPORTANTE: SIEMPRE USAREMOS random_state=RANDOM_SEED\n",
        "clf = LogisticRegression(random_state=RANDOM_SEED, C=1, tol=0.01, max_iter=10).fit(X_train, y_train)\n",
        "err_test = (1 - accuracy_score(y_test, clf.predict(X_test)))*100\n",
        "print(f'Error de clasificación en test (baseline): {err_test:5.1f}%')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VJdQSdDj7iFh"
      },
      "source": [
        "## 3. Exploración/Optimización de hiperparámetros\n",
        "\n",
        "Realiza una exploración y ajuste de los hiperparámetros tolerancia (`tol`), escalado del factor de regularización (`C`), y número de iteraciones máximas (`max_iter`), para minimizar la tasa de error de clasificación en test.\n",
        "\n",
        "Reporta los resultados de los experimentos en una o varias tablas que muestren los valores de los tres hiperparámetros mencionados, además de las tasas de error de clasificación en train y test.\n",
        "\n",
        "Introduce a continuación el código que hayas utilizado para realizar esta exploración/optimización, y asegúrate que el cuaderno conserva la salida de la ejecución de dicho código. Crea celdas de código adicionales si lo necesitas.\n",
        "\n",
        "**IMPORTANTE: usa el parámetro `random_state=RANDOM_SEED` en `LogisticRegression()`**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ENjg6WHG7iFh",
        "outputId": "92604c6f-f922-4f22-ece2-4fe3411d43c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ejecutando (Seed=22)...\n",
            "Fitting 3 folds for each of 24 candidates, totalling 72 fits\n",
            "\n",
            "============================================================\n",
            "RESULTADOS:\n",
            "============================================================\n",
            "Factor C:           100\n",
            "Tolerancia (tol):   0.0001\n",
            "Iteraciones:        2000\n",
            "Error TRAIN:        42.10%\n",
            "Error TEST:         43.36%\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer, make_column_selector\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import MaxAbsScaler, OneHotEncoder\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "print(X_train.dtypes)\n",
        "\n",
        "# 1. PREPROCESAMIENTO\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='median')),\n",
        "    ('scaler', MaxAbsScaler())\n",
        "])\n",
        "\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
        "])\n",
        "#numerica\n",
        "if isinstance(X_train, np.ndarray):\n",
        "    preprocessor = ColumnTransformer(\n",
        "        transformers=[('num', numeric_transformer, list(range(X_train.shape[1])))],\n",
        "        remainder='passthrough'\n",
        "    )\n",
        "    #categorica\n",
        "else:\n",
        "    preprocessor = ColumnTransformer(\n",
        "        transformers=[\n",
        "            ('num', numeric_transformer, make_column_selector(dtype_include=np.number)),\n",
        "            ('cat', categorical_transformer, make_column_selector(dtype_include=['object', 'category']))\n",
        "        ],\n",
        "        remainder='passthrough'\n",
        "    )\n",
        "\n",
        "# 2. PIPELINE BASE\n",
        "clf = Pipeline(steps=[\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('classifier', LogisticRegression(random_state=RANDOM_SEED))\n",
        "])\n",
        "\n",
        "# 3. GRID SEARCH\n",
        "param_grid = [\n",
        "\n",
        "    {\n",
        "        'classifier__solver': ['lbfgs'],\n",
        "        'classifier__C': [0.1, 1, 10, 100],\n",
        "        'classifier__tol': [0.001, 0.0001],\n",
        "        'classifier__max_iter': [2000],\n",
        "        'classifier__class_weight': [None, 'balanced']\n",
        "    },\n",
        "\n",
        "    {\n",
        "        'classifier__solver': ['liblinear'],\n",
        "        'classifier__penalty': ['l2'],\n",
        "        'classifier__C': [0.1, 1, 10, 100],\n",
        "        'classifier__tol': [0.001],\n",
        "        'classifier__max_iter': [2000],\n",
        "        'classifier__class_weight': [None, 'balanced']\n",
        "    }\n",
        "]\n",
        "\n",
        "# 4. EJECUCIÓN\n",
        "print(f\"Ejecutando (Seed={RANDOM_SEED})...\")\n",
        "\n",
        "\n",
        "grid = GridSearchCV(clf, param_grid, cv=3, scoring='accuracy', n_jobs=-1, verbose=1)\n",
        "grid.fit(X_train, y_train)\n",
        "\n",
        "# 5. RESULTADOS\n",
        "best_params = grid.best_params_\n",
        "best_model = grid.best_estimator_\n",
        "\n",
        "err_train = (1 - best_model.score(X_train, y_train)) * 100\n",
        "err_test = (1 - best_model.score(X_test, y_test)) * 100\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"RESULTADOS:\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Factor C:           {best_params['classifier__C']}\")\n",
        "print(f\"Tolerancia (tol):   {best_params['classifier__tol']}\")\n",
        "print(f\"Iteraciones:        {best_params['classifier__max_iter']}\")\n",
        "print(f\"Error TRAIN:        {err_train:.2f}%\")\n",
        "print(f\"Error TEST:         {err_test:.2f}%\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "\n",
        "'''\n",
        "numeric\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='median')),\n",
        "    ('scaler', MaxAbsScaler())\n",
        "])\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[('num', numeric_transformer, list(range(X_train.shape[1])))],\n",
        "    remainder='passthrough'\n",
        ")'''\n",
        "\n",
        "'''\n",
        "categorica\n",
        "numeric_transformer = Pipeline([...])\n",
        "categorical_transformer = Pipeline([...])\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numeric_transformer, make_column_selector(dtype_include=np.number)),\n",
        "        ('cat', categorical_transformer, make_column_selector(dtype_include=['object', 'category']))\n",
        "    ],\n",
        "    remainder='passthrough'\n",
        ")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dBlrG0XQ7iFh"
      },
      "source": [
        "## 4. Determinación de los hiperparámetros óptimos y tasas de error\n",
        "\n",
        "Por último, **modifica** la siguiente celda para que indique cuáles son los valores óptimos de los tres hiperparámetros `C`, `tol` y `max_iter`, así como las correspondientes tasas de error obtenidas en los conjuntos de entrenamiento y test."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UXDPalP17iFh"
      },
      "source": [
        "- **Factor de regularización (`C`):**\n",
        "- **Tolerancia (`tol`):**\n",
        "- **Número máximo de iteraciones (`max_iter`):**\n",
        "- **Tasa de error (%) obtenida en train:**\n",
        "- **Tasa de error (%) obtenida en test:**\n",
        "\n",
        "\n",
        "Nota: los valores de `C`, `tol` y `max_iter` que indiques aquí son los que usarás para participar en la evaluación final."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}